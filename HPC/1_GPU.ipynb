{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Prueba 1 - Vectores - GPU.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zw-Vno_15t-E"
      },
      "source": [
        "# 1 Introducción\n",
        "El siguiente cuaderno realiza la suma de dos vectores, utilizando GPGPU. El algoritmo está basado en la función axpy nivel 1[3], de la biblioteca BLAS[4] que resuelve la ecuación:\n",
        "<center>$Y=\\alpha X + Y$</center>\n",
        "\n",
        "Su objetivo es enseñar a los alumnos como se utiliza Python [2] la plataforma Colab[1] y CUDA[5,6]. Mostrando el funcionamiento y granularidad (grilla, bloque, warps) de sobre una dimensión (x)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cRnhv_7N4Pa"
      },
      "source": [
        "---\n",
        "# 2 Armado del ambiente\n",
        "Instala en el cuaderno el módulo CUDA de Python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z74FNbCszDmw"
      },
      "source": [
        "!pip install pycuda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzQaWRTtc1Zj"
      },
      "source": [
        "---\n",
        "# 3 Desarrollo\n",
        "Ejecuta el Código CPU - GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9c7mZSnu0M3m"
      },
      "source": [
        "# --------------------------------------------\n",
        "#@title 3.1 Parámetros de ejecución { vertical-output: true }\n",
        "\n",
        "cantidad_N =   50000#@param {type: \"number\"}\n",
        "alfa =   1#@param {type: \"number\"}\n",
        "# --------------------------------------------\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "tiempo_total = datetime.now()\n",
        "\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule\n",
        "\n",
        "import numpy\n",
        "\n",
        "# --------------------------------------------\n",
        "# Definición de función que transforma el tiempo en  milisegundos \n",
        "tiempo_en_ms = lambda dt:(dt.days * 24 * 60 * 60 + dt.seconds) * 1000 + dt.microseconds / 1000.0\n",
        "\n",
        "\n",
        "# CPU - Defino la memoria de los vectores en cpu.\n",
        "x_cpu = numpy.random.randn( cantidad_N )\n",
        "x_cpu = x_cpu.astype( numpy.float32() )\n",
        "\n",
        "y_cpu = numpy.random.randn( cantidad_N )\n",
        "y_cpu = y_cpu.astype( numpy.float32() )\n",
        "\n",
        "#tiempo_ini_cpu = datetime.now()\n",
        "\n",
        "r_cpu = numpy.empty_like( x_cpu )\n",
        "\n",
        "# CPU - reservo la memoria GPU.\n",
        "x_gpu = cuda.mem_alloc( x_cpu.nbytes )\n",
        "y_gpu = cuda.mem_alloc( y_cpu.nbytes )\n",
        "\n",
        "# GPU - Copio la memoria al GPU.\n",
        "cuda.memcpy_htod( x_gpu, x_cpu )\n",
        "cuda.memcpy_htod( y_gpu, y_cpu )\n",
        "\n",
        "# CPU - Defino la función kernel que ejecutará en GPU.\n",
        "module = SourceModule(\"\"\"\n",
        "__global__ void kernel_axpy( int n, float alfa, float *X, float *Y )\n",
        "{\n",
        "  int idx = threadIdx.x + blockIdx.x*blockDim.x;\n",
        "  if( idx < n )\n",
        "  {\n",
        "    Y[idx]  = alfa*X[idx] + Y[idx];\n",
        "  }\n",
        "}\n",
        "\"\"\") \n",
        "# CPU - Genero la función kernel.\n",
        "kernel = module.get_function(\"kernel_axpy\")\n",
        "\n",
        "tiempo_gpu = datetime.now()\n",
        "\n",
        "# GPU - Ejecuta el kernel.\n",
        "# TODO: Falta consultar limites del GPU, para armar las dimensiones correctamente.\n",
        "dim_hilo = 256\n",
        "dim_bloque = numpy.int( (cantidad_N+dim_hilo-1) / dim_hilo )\n",
        "print( \"Thread x: \", dim_hilo, \", Bloque x:\", dim_bloque )\n",
        "\n",
        "#TODO: Ojo, con los tipos de las variables en el kernel.\n",
        "kernel( numpy.int32(cantidad_N),numpy.float32(alfa), x_gpu, y_gpu, block=( dim_hilo, 1, 1 ),grid=(dim_bloque, 1,1) )\n",
        "\n",
        "tiempo_gpu = datetime.now() - tiempo_gpu\n",
        "\n",
        "# GPU - Copio el resultado desde la memoria GPU.\n",
        "cuda.memcpy_dtoh( r_cpu, y_gpu )\n",
        "\n",
        "\"\"\"\n",
        "# CPU - Informo el resutlado.\n",
        "print( \"------------------------------------\")\n",
        "print( \"X: \" )\n",
        "print( x_cpu )\n",
        "print( \"------------------------------------\")\n",
        "print( \"Y: \" )\n",
        "print( y_cpu )\n",
        "print( \"------------------------------------\")\n",
        "print( \"R: \" )\n",
        "print( r_cpu )\n",
        "\"\"\"\n",
        "\n",
        "tiempo_total = datetime.now() - tiempo_total\n",
        "\n",
        "print( \"Cantidad de elementos: \", cantidad_N )\n",
        "print( \"Thread x: \", dim_hilo, \", Bloque x:\", dim_bloque )\n",
        "print(\"Tiempo CPU: \", tiempo_en_ms( tiempo_total ), \"[ms]\" )\n",
        "print(\"Tiempo GPU: \", tiempo_en_ms( tiempo_gpu   ), \"[ms]\" )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EALIlyyG6iqP"
      },
      "source": [
        "---\n",
        "# 4 Tabla de pasos de ejecución del programa\n",
        "\n",
        "\n",
        " Procesador | Funciòn | Detalle\n",
        "------------|---------|----------\n",
        "CPU      |  @param                | Lectura del tamaño de vectores desde Colab.\n",
        "CPU      |  import                | Importa los módulos para funcionar.\n",
        "CPU      |  datetime.now()        | Toma el tiempo actual.\n",
        "CPU      |  numpy.random.randn( Cantidad_N ) | Inicializa los vectoes A, B y R.\n",
        "**GPU**  |  cuda.mem_alloc()      | Reserva la memoria en GPU.\n",
        "**GPU**  |  cuda.memcpy_htod()    | Copia las memorias desde el CPU al GPU.\n",
        "CPU      |  SourceModule()        | Define el código del kernel \n",
        "CPU      |  module.get_function() | Genera la función del kernel GPU\n",
        "CPU      |  dim_tx/dim_bx         | Calcula las dimensiones.\n",
        "**GPU**  |  kernel()              | Ejecuta el kernel en GPU\n",
        "CPU      |  cuda.memcpy_dtoh( )   | Copia el resultado desde GPU memoria A a CPU memoria R.\n",
        "CPU      |  print()               | Informo los resultados.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzgZkrQD-UTy"
      },
      "source": [
        "---\n",
        "# 5 Conclusiones\n",
        "\n",
        "Las conclusiones son explicadas en clase....\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hn6HOCYEjyY"
      },
      "source": [
        "---\n",
        "# 6 Bibliografia\n",
        "\n",
        "[1] MARKDOWN SYNTAX Colab: [PDF](https://github.com/wvaliente/SOA_HPC/blob/main/Documentos/markdown-cheatsheet-online.pdf)\n",
        "\n",
        "[2] Introducción a Python: [Página Colab](https://github.com/wvaliente/SOA_HPC/blob/main/Documentos/Python_Basico.ipynb) \n",
        "\n",
        "[3] Función Axpy de biblioteca BLAS: [Referencia](https://software.intel.com/content/www/us/en/develop/documentation/mkl-developer-reference-c/top/blas-and-sparse-blas-routines/blas-routines/blas-level-1-routines-and-functions/cblas-axpy.html)\n",
        "\n",
        "[4] Biblioteca BLAS: [Referencia](http://www.netlib.org/blas/)\n",
        "\n",
        "[5] Documentación PyCUDA: [WEB](https://documen.tician.de/pycuda/index.html)\n",
        "\n",
        "[6] Repositorio de PyCUDA: [WEB](https://pypi.python.org/pypi/pycuda)\n",
        "\n",
        "\n"
      ]
    }
  ]
}